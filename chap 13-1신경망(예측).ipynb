{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b700ed8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.1.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (61.2.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gksxk\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.11.23 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.11.0 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 설치\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131852a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈설치\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.datasets import load_boston\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28db32e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gksxk\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'boston_house_prices.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boston 데이타셋 불러오기 : dictionary구조를 DataFrame 변환 \n",
    "boston=load_boston()\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249270c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bost= pd.DataFrame(boston.data , columns= boston.feature_names)\n",
    "bost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2a3f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boston dataset의 target array는 주택 가격임. 이를 medv 컬럼으로 DataFrame에 추가함. \n",
    "bost['medv'] = boston.target\n",
    "bost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704bba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 표준화 후 훈령용, 테스트용 자료 분류 : fixed\n",
    "from sklearn.preprocessing import StandardScaler  # 표준화 패키지 라이브러리 \n",
    "y_target= bost['medv']\n",
    "x_data = bost.drop(['medv'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61db0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화(Z)\n",
    "x_data = StandardScaler().fit_transform(x_data) # x_data객체에 표준화한 데이터를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c567f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : 404\n",
      "테스트 데이터의 크기 : 102\n"
     ]
    }
   ],
   "source": [
    "num_of_train = int(len(x_data) * 0.8) # 데이터의 전체 길이의 80%에 해당하는 길이값을 구한다.\n",
    "num_of_test = int(len(x_data) - num_of_train) # 전체 길이에서 80%에 해당하는 길이를 뺀다.\n",
    "print('훈련 데이터의 크기 :',num_of_train)\n",
    "print('테스트 데이터의 크기 :',num_of_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fd8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_data[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
    "y_test = y_target[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
    "x_train = x_data[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
    "y_train = y_target[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f598f40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 테스트 데이터 :\n",
      "[[ 4.41236983 -0.48772236  1.01599907 ...  0.80657583 -0.2983844\n",
      "   2.06433044]\n",
      " [ 7.48364564 -0.48772236  1.01599907 ...  0.80657583  0.31024714\n",
      "   1.4475658 ]\n",
      " [ 1.99029374 -0.48772236  1.01599907 ...  0.80657583  0.14852285\n",
      "   1.49802836]\n",
      " ...\n",
      " [-0.41344658 -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
      "  -0.98304761]\n",
      " [-0.40776407 -0.48772236  0.11573841 ...  1.17646583  0.4032249\n",
      "  -0.86530163]\n",
      " [-0.41500016 -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
      "  -0.66905833]]\n",
      "y 테스트 데이터 :\n",
      "[8.5, 5.0, 11.9, 27.9, 17.2, 27.5, 15.0, 17.2, 17.9, 16.3, 7.0, 7.2, 7.5, 10.4, 8.8, 8.4, 16.7, 14.2, 20.8, 13.4, 11.7, 8.3, 10.2, 10.9, 11.0, 9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4, 9.6, 8.7, 8.4, 12.8, 10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13.0, 13.4, 15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20.0, 16.4, 17.7, 19.5, 20.2, 21.4, 19.9, 19.0, 19.1, 19.1, 20.1, 19.9, 19.6, 23.2, 29.8, 13.8, 13.3, 16.7, 12.0, 14.6, 21.4, 23.0, 23.7, 25.0, 21.8, 20.6, 21.2, 19.1, 20.6, 15.2, 7.0, 8.1, 13.6, 20.1, 21.8, 24.5, 23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22.0, 11.9]\n"
     ]
    }
   ],
   "source": [
    "print('X 테스트 데이터 :')\n",
    "print(x_test)\n",
    "print('y 테스트 데이터 :')\n",
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23014d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston Housing Dataset 회귀 모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=52, activation='relu', input_shape=(13,)),\n",
    "    tf.keras.layers.Dense(units=39, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=26, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b67d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 52)                728       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 39)                2067      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 26)                1040      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,862\n",
      "Trainable params: 3,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec8a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 46ms/step - loss: 724.1619 - val_loss: 476.9442\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 711.8393 - val_loss: 467.0819\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 699.6324 - val_loss: 454.9681\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 681.1693 - val_loss: 438.7625\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 653.5323 - val_loss: 415.7303\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 610.5284 - val_loss: 383.0520\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 544.0511 - val_loss: 338.2750\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 446.1647 - val_loss: 281.7770\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 324.2706 - val_loss: 221.1586\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 188.3266 - val_loss: 178.5585\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 92.3781 - val_loss: 168.2289\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 57.7696 - val_loss: 164.2031\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 41.4562 - val_loss: 148.2491\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 30.1451 - val_loss: 137.6103\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 23.6100 - val_loss: 135.9651\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 19.5411 - val_loss: 136.8950\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 17.0450 - val_loss: 137.2009\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 15.6444 - val_loss: 137.0000\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 14.6382 - val_loss: 138.7841\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.0286 - val_loss: 140.0969\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.6264 - val_loss: 139.4065\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.1988 - val_loss: 136.7050\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.7614 - val_loss: 134.1615\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.3757 - val_loss: 134.0930\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.0533 - val_loss: 133.7499\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.7817 - val_loss: 133.1352\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.5316 - val_loss: 132.2859\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.4120 - val_loss: 130.9274\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 10.9490 - val_loss: 131.3144\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.0043 - val_loss: 130.9056\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 10.7350 - val_loss: 128.5518\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10.4901 - val_loss: 128.0750\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 10.3029 - val_loss: 126.6820\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 10.0062 - val_loss: 126.0580\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 9.9662 - val_loss: 125.2520\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 9.7625 - val_loss: 124.8171\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 9.6785 - val_loss: 122.9769\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 9.4154 - val_loss: 121.6623\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 9.1612 - val_loss: 120.9071\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 8.9994 - val_loss: 121.4465\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 8.8850 - val_loss: 120.9072\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 8.7026 - val_loss: 118.7922\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 8.6118 - val_loss: 116.8720\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 8.3923 - val_loss: 114.9211\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 8.2461 - val_loss: 113.3671\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 8.2156 - val_loss: 112.4237\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 8.1197 - val_loss: 112.4026\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 7.7613 - val_loss: 112.1746\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 7.6015 - val_loss: 110.7948\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 7.4626 - val_loss: 108.8120\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 7.4108 - val_loss: 108.0821\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 7.5845 - val_loss: 108.6897\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 7.5633 - val_loss: 108.2015\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 7.0936 - val_loss: 106.7815\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 6.9637 - val_loss: 104.9033\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.8608 - val_loss: 102.6697\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.8580 - val_loss: 102.4936\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 6.7133 - val_loss: 102.5568\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 6.7235 - val_loss: 101.7739\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.5958 - val_loss: 100.7950\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.4480 - val_loss: 101.6962\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.4700 - val_loss: 100.9611\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.3268 - val_loss: 99.0941\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6.6314 - val_loss: 97.5033\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.2489 - val_loss: 97.8566\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 6.2617 - val_loss: 96.9728\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 6.1820 - val_loss: 95.6843\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 6.0962 - val_loss: 96.0323\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.9592 - val_loss: 95.9875\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 6.2179 - val_loss: 95.4312\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.8823 - val_loss: 92.1211\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.8090 - val_loss: 91.7944\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.7178 - val_loss: 92.7338\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.6084 - val_loss: 93.2456\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.5680 - val_loss: 93.4978\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.5722 - val_loss: 93.0015\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.5403 - val_loss: 91.9999\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.5904 - val_loss: 90.0552\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.4187 - val_loss: 89.2099\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.3336 - val_loss: 88.4649\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.3649 - val_loss: 88.5992\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.2753 - val_loss: 88.6656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.2209 - val_loss: 88.1554\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.1821 - val_loss: 87.8066\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.1705 - val_loss: 86.3771\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.1664 - val_loss: 84.7146\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.1261 - val_loss: 86.7774\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.1352 - val_loss: 85.9764\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.0069 - val_loss: 87.0269\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 5.0220 - val_loss: 87.4089\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.1254 - val_loss: 86.8195\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.9387 - val_loss: 85.6292\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 4.8921 - val_loss: 83.3167\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.8708 - val_loss: 82.6973\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 4.8438 - val_loss: 81.3485\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.7968 - val_loss: 81.0497\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 4.7535 - val_loss: 81.5978\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.8577 - val_loss: 83.3625\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.7182 - val_loss: 82.5450\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.7489 - val_loss: 81.9831\n"
     ]
    }
   ],
   "source": [
    "# 회귀 모델 학습 : epochs~신경망을 전체 한번 학습하여 나온 결과\n",
    "# batch_size~train-set의 80%의 자료를 40개씩 소그룹(sub-group) 10개로 나누어 빠르게 학습\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "625015fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 회귀 모델 학습 결과 시각화 : loss=mse(훈련용), val_loss(검증용)   \n",
    "# loss가 잘 줄지 않으면 활성함수를 바꿔본다\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71149fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 36.3403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.34031295776367"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀 모델 평가\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92eafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 주택 가격과 예측 주택 가격 시각화\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93515f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "MSE : 36.340 , RMSE : 6.028\n"
     ]
    }
   ],
   "source": [
    "# 회귀 모델 평가\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse , rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8100e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
